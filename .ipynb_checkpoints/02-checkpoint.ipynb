{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "all_data=data/SICK/SICK_all.txt\n",
      "char_embedding_dim=50\n",
      "cnt=10\n",
      "data_path=data\n",
      "min_word_freq=2\n",
      "model_name=02\n",
      "result_path=result/\n",
      "save_path=model/\n",
      "test_data=data/SICK/SICK_test_annotated.txt\n",
      "train_data=data/SICK/SICK_new_train.txt\n",
      "use_fp64=False\n",
      "validation_data=data/SICK/SICK_new_trial.txt\n",
      "word2vec_path=embeddings/GoogleNews-vectors-negative300.txt\n",
      "word_embedding_dim=300\n",
      "2556 54\n",
      "Load word2vec_norm file embeddings/GoogleNews-vectors-negative300.txt\n",
      "2556 300\n",
      "vocab_size=2556\n",
      "preloaded vectors\n",
      "dataset read\n",
      "32\n",
      "16\n",
      "pad_to_max_len_sentence_and_word_len\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import collections\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#comment: for server only\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg') \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "\n",
    "# Model Hyperparameters\n",
    "flags=tf.flags\n",
    "\n",
    "flags.DEFINE_string('word2vec_path','embeddings/GoogleNews-vectors-negative300.txt','Word2vec file with pre-trained embeddings')\n",
    "flags.DEFINE_string('data_path','data','data set path')\n",
    "flags.DEFINE_string('min_word_freq','2','Minimum word frequency')\n",
    "flags.DEFINE_string('save_path','model/','STS model output directory')\n",
    "flags.DEFINE_string('result_path','result/','data set path')\n",
    "flags.DEFINE_string('test_data',\"data/SICK/SICK_test_annotated.txt\",'Test data')\n",
    "flags.DEFINE_string('validation_data',\"data/SICK/SICK_new_trial.txt\",'Validation data')\n",
    "flags.DEFINE_string('train_data',\"data/SICK/SICK_new_train.txt\",'Train data')\n",
    "flags.DEFINE_string('all_data',\"data/SICK/SICK_all.txt\",'Train data')\n",
    "flags.DEFINE_string('cnt',\"10\",'Number of samples to show')\n",
    "flags.DEFINE_string('model_name','02','Filename of the model file')\n",
    "flags.DEFINE_integer('word_embedding_dim',300,'Dimensionality of word embedding')\n",
    "flags.DEFINE_integer('char_embedding_dim',50,'Dimensionality of char embedding')\n",
    "flags.DEFINE_bool('use_fp64',False,'Train using 64-bit floats instead of 32bit floats')\n",
    "\n",
    "\n",
    "\n",
    "FLAGS=flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print('Parameters:')\n",
    "for attr,value in sorted(FLAGS.__flags.items()):\n",
    "    print('{}={}'.format(attr,value))\n",
    "    \n",
    "    \n",
    "\n",
    "# model parameters\n",
    "class Config(object):\n",
    "    init_scale=0.2\n",
    "    learning_rate=.01\n",
    "    max_grad_norm=1.\n",
    "    keep_prob=0.5\n",
    "    lr_decay=0.98\n",
    "    batch_size=30\n",
    "    lr_max_epoch=8##this is for learning rate epoch\n",
    "    train_max_epoch=5\n",
    "    num_layer=1\n",
    "    num_units=50\n",
    "    patience=5\n",
    "    \n",
    "config=Config()\n",
    "config_gpu = tf.ConfigProto()\n",
    "config_gpu.gpu_options.allow_growth = True\n",
    "    \n",
    "def data_type():\n",
    "    return tf.float64 if FLAGS.use_fp64 else tf.float32\n",
    "\n",
    "\n",
    "\n",
    "class Input(object):\n",
    "    def __init__(self,sentences_A,sentencesA_length,sentences_B,sentencesB_length,relatedness_scores):\n",
    "        self.sentences_A=sentences_A\n",
    "        self.sentencesA_length=sentencesA_length\n",
    "        self.sentences_B=sentences_B\n",
    "        self.sentencesB_length=sentencesB_length\n",
    "        self.relatedness_scores=relatedness_scores\n",
    "    \n",
    "    def sentences_A(self):\n",
    "        return self.sentences_A\n",
    "    \n",
    "    def sentencesA_length(self):\n",
    "        return self.sentencesA_length\n",
    "    \n",
    "    def sentences_B(self):\n",
    "        return self.sentences_B\n",
    "    \n",
    "    def sentencesA_length(self):\n",
    "        return self.sentencesB_length\n",
    "    \n",
    "    def relatedness_scores(self):\n",
    "        return self.relatedness_scores\n",
    "\n",
    "\n",
    "'''\n",
    "Reads SICK file. Take note of the header line.\n",
    "'''\n",
    "def read_input_file(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        f.readline() # removes header line/column labels\n",
    "        sentences_A = []\n",
    "        sentencesA_length = []\n",
    "        sentences_B = []\n",
    "        sentencesB_length = []\n",
    "        relatedness_scores = []\n",
    "        while True:\n",
    "            line=f.readline()\n",
    "            if not line: break\n",
    "\n",
    "            sentence_A=line.split('\\t')[1]\n",
    "            sentence_B=line.split('\\t')[2]\n",
    "            relatedness_score=line.split('\\t')[3]    \n",
    "            \n",
    "            words = sentence_A.split()\n",
    "            sentencesA_length.append(len(words))\n",
    "            sentences_A.append(words)\n",
    "            \n",
    "            words = sentence_B.split()\n",
    "            sentencesB_length.append(len(words))\n",
    "            sentences_B.append(words)\n",
    "            \n",
    "            relatedness_scores.append(((float(relatedness_score) - 1) / 4 )) # convert scores to [0,1] values\n",
    "    assert len(sentences_A)==len(sentencesA_length)==len(sentences_B)==len(sentencesB_length)==len(relatedness_scores)\n",
    "    return Input(sentences_A,sentencesA_length,sentences_B,sentencesB_length,relatedness_scores)\n",
    "\n",
    "\n",
    "def generate_word2id_dictionary(texts, min_freq=-1, insert_words=None, lowercase=False, replace_digits=False):\n",
    "    counter = collections.Counter()\n",
    "    for text in texts:\n",
    "        if lowercase:\n",
    "            text = text.lower()\n",
    "        if replace_digits:\n",
    "            text = re.sub(r'\\d', '0', text)\n",
    "        counter.update(text.strip().split())\n",
    "\n",
    "    word2id = collections.OrderedDict()\n",
    "    if insert_words is not None:\n",
    "        for word in insert_words:\n",
    "            word2id[word] = len(word2id)\n",
    "    word_count_list = counter.most_common()\n",
    "\n",
    "    for (word, count) in word_count_list:\n",
    "        if min_freq <= 0 or count >= min_freq:\n",
    "            word2id[word] = len(word2id)\n",
    "\n",
    "    return word2id\n",
    "\n",
    "# Create an OrderedDict of words and characters and their ids based on their frequency\n",
    "dataset = read_input_file(FLAGS.all_data)\n",
    "sentences = dataset.sentences_A + dataset.sentences_B\n",
    "word2id = generate_word2id_dictionary([\" \".join(sentence) for sentence in sentences], \n",
    "                                        int(FLAGS.min_word_freq), \n",
    "                                        insert_words=[\"<unk>\"], \n",
    "                                        lowercase=False, \n",
    "                                        replace_digits=False)\n",
    "char2id = generate_word2id_dictionary([\" \".join([\" \".join(list(word)) for word in sentence]) for sentence in sentences], \n",
    "                                        min_freq=-1, \n",
    "                                        insert_words=[\"<cunk>\"], \n",
    "                                        lowercase=False, \n",
    "                                        replace_digits=False)\n",
    "\n",
    "\n",
    "\n",
    "## vocab size\n",
    "word_vocab_size = len(word2id)\n",
    "\n",
    "char_vocab_size = len(char2id)\n",
    "print(word_vocab_size, char_vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Given the word2id, load its pretrained vectors into memory\n",
    "def preload_vectors(word2vec_path, word2id, vocab_size, emb_dim):\n",
    "    if word2vec_path:\n",
    "        print('Load word2vec_norm file {}'.format(word2vec_path))\n",
    "        with open(word2vec_path,'r') as f:\n",
    "            header=f.readline()\n",
    "            print(vocab_size, emb_dim)\n",
    "            scale = np.sqrt(3.0 / emb_dim)\n",
    "            init_W = np.random.uniform(-scale, scale, [vocab_size, emb_dim])\n",
    "            \n",
    "            print('vocab_size={}'.format(vocab_size))\n",
    "            while True:\n",
    "                line=f.readline()\n",
    "                if not line:break\n",
    "                word=line.split()[0]\n",
    "                if word in word2id:\n",
    "                    init_W[word2id[word]] = np.array(line.split()[1:], dtype = \"float32\")\n",
    "    return init_W\n",
    "\n",
    "init_W = preload_vectors(FLAGS.word2vec_path, word2id, word_vocab_size, FLAGS.word_embedding_dim)\n",
    "\n",
    "print(\"preloaded vectors\")\n",
    "\n",
    "\n",
    "def map_text_to_ids(text, word2id, start_token=None, end_token=None, unk_token=None, lowercase=False, replace_digits=False):\n",
    "    ids = []\n",
    "\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if replace_digits:\n",
    "        text = re.sub(r'\\d', '0', text)\n",
    "\n",
    "    if start_token != None:\n",
    "        text = start_token + \" \" + text\n",
    "    if end_token != None:\n",
    "        text = text + \" \" + end_token\n",
    "    for word in text.strip().split():\n",
    "        if word in word2id:\n",
    "            ids.append(word2id[word])\n",
    "        elif unk_token != None:\n",
    "            ids.append(word2id[unk_token])\n",
    "    return ids\n",
    "\n",
    "\n",
    "def read_dataset(filename, lowercase_words, lowercase_chars, replace_digits, word2id, char2id):\n",
    "    dataset = []\n",
    "    data = read_input_file(filename)\n",
    "    sentences = [data.sentences_A, data.sentences_B]\n",
    "    max_sentence_len = 0\n",
    "    max_word_len = 0\n",
    "    for i in range(len(data.sentences_A)):\n",
    "\n",
    "        # map text to ids\n",
    "        senA_word_ids = map_text_to_ids(\" \".join(sentences[0][i]), word2id, None, None, \"<unk>\", lowercase=False, replace_digits=False)\n",
    "        senA_char_ids = [map_text_to_ids(\" \".join(list(word)), char2id, None, None, \"<cunk>\", lowercase=False, replace_digits=False) for word in sentences[0][i]]\n",
    "\n",
    "        senB_word_ids = map_text_to_ids(\" \".join(sentences[1][i]), word2id, None, None, \"<unk>\", lowercase=False, replace_digits=False)\n",
    "        senB_char_ids = [map_text_to_ids(\" \".join(list(word)), char2id, None, None, \"<cunk>\", lowercase=False, replace_digits=False) for word in sentences[1][i]]\n",
    "\n",
    "        assert(len(senA_word_ids) == len(senA_char_ids))\n",
    "        assert(len(senB_word_ids) == len(senB_char_ids))\n",
    "        \n",
    "        \n",
    "        senA_len = len(senA_word_ids)\n",
    "        senA_words_len = [len(word) for word in senA_char_ids]\n",
    "        senB_len = len(senB_word_ids)\n",
    "        senB_words_len = [len(word) for word in senB_char_ids]\n",
    "        \n",
    "        max_sentence_len = max(max_sentence_len, senA_len, senB_len)\n",
    "        max_word_len = max(max(senA_words_len), max(senB_words_len), max_word_len)\n",
    "        \n",
    "        dataset.append((senA_word_ids, senA_len, senA_char_ids, senA_words_len, senB_word_ids, senB_len, senB_char_ids, senB_words_len, data.relatedness_scores[i]))\n",
    "    return dataset, max_sentence_len, max_word_len\n",
    "\n",
    "data_train, max_sentence_len_train, max_word_len_train = read_dataset(FLAGS.train_data, False, False, False, word2id, char2id)\n",
    "data_dev, max_sentence_len_dev, max_word_len_dev = read_dataset(FLAGS.validation_data, False, False, False, word2id, char2id)\n",
    "data_test, max_sentence_len_test, max_word_len_test = read_dataset(FLAGS.test_data, False, False, False, word2id, char2id)\n",
    "print(\"dataset read\")\n",
    "\n",
    "'''\n",
    "Get the max_sentence_len and max_word_len\n",
    "'''\n",
    "## Check the sentence\n",
    "# max_sentence_len = sorted(([(len(sentence), sentence) for sentence in sentences]))[-1]\n",
    "max_sentence_len = max(max_sentence_len_train, max_sentence_len_test, max_sentence_len_dev)\n",
    "print(max_sentence_len)\n",
    "\n",
    "## Check the word\n",
    "# max_word_len = sorted(([(len(word), word) for word in word2id]))[-1]\n",
    "max_word_len = max(max_word_len_train, max_word_len_test, max_word_len_dev)\n",
    "print(max_word_len)\n",
    "\n",
    "\n",
    "def pad_to_max_len_sentence_and_word_len(data, max_sentence_len, max_word_len):\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        senA_word_ids = data[i][0]\n",
    "        senB_word_ids = data[i][4]\n",
    "        senA_char_ids = data[i][2]\n",
    "        senB_char_ids = data[i][6]\n",
    "        senA_words_len = data[i][3]\n",
    "        senB_words_len = data[i][7]\n",
    "        senA_len = data[i][1]\n",
    "        senB_len = data[i][5]\n",
    "        relatedness_scores = data[i][8]\n",
    "        \n",
    "        # pad values to max_sentence_len \n",
    "        senA_word_ids += [0] * (max_sentence_len - len(senA_word_ids))\n",
    "        senB_word_ids += [0] * (max_sentence_len - len(senB_word_ids))\n",
    "               \n",
    "        assert(len(senA_word_ids) == len(senB_word_ids))\n",
    "        \n",
    "        # pad values to max_word_len and pad each sentence to max_sentence_len\n",
    "        senA_char_ids_wl = [word + ([0] * (max_word_len - len(word))) for word in senA_char_ids]\n",
    "        senA_char_ids_sl = [([0] * (max_word_len))] * (max_sentence_len - len(senA_char_ids_wl))\n",
    "        senA_char_ids = senA_char_ids_wl + senA_char_ids_sl\n",
    "\n",
    "        senB_char_ids_wl = [word + ([0] * (max_word_len - len(word))) for word in senB_char_ids]\n",
    "        senB_char_ids_sl = [([0] * (max_word_len))] * (max_sentence_len - len(senB_char_ids_wl))\n",
    "        senB_char_ids = senB_char_ids_wl + senB_char_ids_sl\n",
    "\n",
    "        # pad word lengths to max_sentence_len\n",
    "        senA_words_len = senA_words_len + ([0] * (max_sentence_len - len(senA_words_len)))\n",
    "        senB_words_len = senB_words_len + ([0] * (max_sentence_len - len(senB_words_len)))\n",
    "        \n",
    "        dataset.append((senA_word_ids, senA_len, senA_char_ids, senA_words_len, senB_word_ids, senB_len, senB_char_ids, senB_words_len, relatedness_scores))\n",
    "    return dataset\n",
    "\n",
    "data_train = pad_to_max_len_sentence_and_word_len(data_train, max_sentence_len, max_word_len)\n",
    "data_dev = pad_to_max_len_sentence_and_word_len(data_dev, max_sentence_len, max_word_len)\n",
    "data_test = pad_to_max_len_sentence_and_word_len(data_test, max_sentence_len, max_word_len)\n",
    "\n",
    "zipped_train = zip(*data_train)\n",
    "zipped_dev = zip(*data_dev)\n",
    "zipped_test = zip(*data_test)\n",
    "len(zipped_train[3][0])\n",
    "\n",
    "print(\"pad_to_max_len_sentence_and_word_len\")\n",
    "\n",
    "\n",
    "def next_batch(start,end,input):\n",
    "    senA_word_ids = input[0][start:end]\n",
    "    senA_len = input[1][start:end]\n",
    "    senA_char_ids = input[2][start:end]\n",
    "    senA_words_len = input[3][start:end]\n",
    "    senB_word_ids = input[4][start:end]\n",
    "    senB_len = input[5][start:end]\n",
    "    senB_char_ids = input[6][start:end]\n",
    "    senB_words_len = input[7][start:end]\n",
    "    relatedness_scores = np.reshape(input[8][start:end],(-1))\n",
    "    return Batch(senA_word_ids, senA_len, senA_char_ids, senA_words_len, senB_word_ids, senB_len, senB_char_ids, senB_words_len, relatedness_scores)\n",
    "\n",
    "\n",
    "class Batch(object):\n",
    "    def __init__(self,senA_word_ids, senA_len, senA_char_ids, senA_words_len, senB_word_ids, senB_len, senB_char_ids, senB_words_len, relatedness_scores):\n",
    "        self.senA_word_ids = senA_word_ids\n",
    "        self.senA_len = senA_len\n",
    "        self.senA_char_ids = senA_char_ids\n",
    "        self.senA_words_len = senA_words_len\n",
    "        self.senB_word_ids = senB_word_ids\n",
    "        self.senB_len = senB_len\n",
    "        self.senB_char_ids = senB_char_ids\n",
    "        self.senB_words_len = senB_words_len\n",
    "        self.relatedness_scores = relatedness_scores\n",
    "    def senA_word_ids(self):\n",
    "        return self.senA_word_ids\n",
    "    \n",
    "    def senA_len(self):\n",
    "        return self.senA_len\n",
    "    \n",
    "    def senA_char_ids(self):\n",
    "        return self.senA_char_ids\n",
    "    \n",
    "    def senA_words_len(self):\n",
    "        return self.senA_words_len\n",
    "    \n",
    "    def senB_word_ids(self):\n",
    "        return self.senB_word_ids\n",
    "    \n",
    "    def senB_len(self):\n",
    "        return self.senB_len\n",
    "    \n",
    "    def senB_char_ids(self):\n",
    "        return self.senB_char_ids\n",
    "    \n",
    "    def senB_words_len(self):\n",
    "        return self.senB_words_len\n",
    "    \n",
    "    def relatedness_scores(self):\n",
    "        return self.relatedness_scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_model\n",
      "training..\n",
      ">>: Model/word_embeddings:0\n",
      ">>: Model/siamese_final/RNN/MultiRNNCell/Cell0/LSTMCell/W_0:0\n",
      ">>: Model/siamese_final/RNN/MultiRNNCell/Cell0/LSTMCell/B:0\n",
      "Total batch size: 116, data size: 3499, batch size: 30\n",
      "1.0 0.5 0.98 8 5 1\n",
      "Epoch 0 Learning rate: 0.00999999977648\n",
      "Average cost:\t0.000301723111549 >\n",
      "Valid cost:\t0.0474858470261 >\n",
      "patience: 5\n",
      "Epoch 1 Learning rate: 0.00999999977648\n",
      "Average cost:\t0.000201588271764 >\n",
      "Valid cost:\t0.0427977032959 >\n",
      "patience: 5\n",
      "Epoch 2 Learning rate: 0.00999999977648\n",
      "Average cost:\t0.000145685537879 >\n",
      "Valid cost:\t0.0402670055628 >\n",
      "patience: 5\n",
      "Epoch 3 Learning rate: 0.00999999977648\n",
      "Average cost:\t0.000143615978545 >\n",
      "Valid cost:\t0.0382386781275 >\n",
      "patience: 5\n",
      "Epoch 4 Learning rate: 0.00999999977648\n",
      "Average cost:\t0.000136315726258 >\n",
      "Valid cost:\t0.03590965271 >\n",
      "patience: 5\n",
      "0.034764\n",
      "Pearson: (0.68566554561803827, 0.0)\n",
      "Execution time: 1486141652.41\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGHCAYAAACqI7gCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe15c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_model(input_,input_length,dropout_):##should try this\n",
    "    rnn_cell=tf.nn.rnn_cell.LSTMCell(config.num_units)##why 50?\n",
    "    rnn_cell=tf.nn.rnn_cell.DropoutWrapper(rnn_cell,output_keep_prob=dropout_)\n",
    "    rnn_cell=tf.nn.rnn_cell.MultiRNNCell([rnn_cell]*config.num_layer)\n",
    "        \n",
    "    outputs,last_states=tf.nn.dynamic_rnn(\n",
    "        cell=rnn_cell,\n",
    "        dtype=data_type(),\n",
    "        sequence_length=input_length,\n",
    "        inputs=input_\n",
    "    )\n",
    "    return outputs,last_states\n",
    "\n",
    "print(\"build_model\")\n",
    "print(\"training..\")\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    initializer=tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "    with tf.variable_scope('Model',initializer=initializer):\n",
    "        \n",
    "        # word embedding\n",
    "        sentences_A = tf.placeholder(tf.int32, shape = ([None, max_sentence_len]), name='sentences_A')\n",
    "        sentencesA_length = tf.placeholder(tf.int32, shape=([None]),name='sentencesA_length')\n",
    "        sentences_B = tf.placeholder(tf.int32, shape = ([None, max_sentence_len]), name='sentences_B')\n",
    "        sentencesB_length = tf.placeholder(tf.int32, shape=([None]), name='sentencesB_length')\n",
    "        labels = tf.placeholder(tf.float32, shape=([None]),name='relatedness_score_label')\n",
    "        dropout_f = tf.placeholder(tf.float32)\n",
    "\n",
    "        # fine-tune by setting trainable to True\n",
    "        W = tf.Variable(tf.constant(0.0, shape = [word_vocab_size,FLAGS.word_embedding_dim]),trainable = True, name='word_embeddings')\n",
    "        embedding_placeholder = tf.placeholder(tf.float32, shape = [word_vocab_size, FLAGS.word_embedding_dim])\n",
    "        embedding_init = W.assign(embedding_placeholder)\n",
    "\n",
    "        # sentences_A_word_emb (30, 32, 300)\n",
    "        sentences_A_word_emb = tf.nn.embedding_lookup(params=embedding_init,ids=sentences_A)\n",
    "        sentences_B_word_emb = tf.nn.embedding_lookup(params=embedding_init,ids=sentences_B)\n",
    "        \n",
    "\n",
    "#         #character embedding\n",
    "#         # C (131, 50)\n",
    "#         C = tf.Variable(tf.random_uniform([char_vocab_size, FLAGS.char_embedding_dim], -1.0, 1.0),trainable=True,name=\"char_embeddings\")\n",
    "#         # sentences_words_A (30, 32, 16)\n",
    "#         sentences_words_A = tf.placeholder(tf.int32, shape = ([None, max_sentence_len, max_word_len]), name='sentences_words_A')\n",
    "#         # sentencesA_words_length (30, 32)\n",
    "#         sentencesA_words_length = tf.placeholder(tf.int32, shape=([None, max_sentence_len]),name='sentencesA_words_length')    \n",
    "        \n",
    "#         sentences_words_B = tf.placeholder(tf.int32, shape = ([None, max_sentence_len, max_word_len]), name='sentences_words_B')\n",
    "#         sentencesB_words_length = tf.placeholder(tf.int32, shape=([None, max_sentence_len]),name='sentencesB_words_length')    \n",
    "        \n",
    "#         # sentences_A_char_emb (30, 32, 16, 50)\n",
    "#         sentences_A_char_emb = tf.nn.embedding_lookup(params = C, ids = sentences_words_A)\n",
    "#         sentences_B_char_emb = tf.nn.embedding_lookup(params = C, ids = sentences_words_B)\n",
    "            \n",
    "#         #reshape char embedding\n",
    "#         # sentences_A_char_emb_1 (960, 16, 50)\n",
    "#         sentences_A_char_emb_1 = tf.reshape(sentences_A_char_emb, shape = ([-1, max_word_len, FLAGS.char_embedding_dim]))\n",
    "#         # sentencesA_words_length_1 (960,)\n",
    "#         sentencesA_words_length_1 = tf.reshape(sentencesA_words_length, shape = ([-1]))\n",
    "#         sentences_B_char_emb_1 = tf.reshape(sentences_B_char_emb, shape = ([-1, max_word_len, FLAGS.char_embedding_dim]))\n",
    "#         sentencesB_words_length_1 = tf.reshape(sentencesB_words_length, shape = ([-1]))\n",
    "\n",
    "#         with tf.variable_scope('siamese_char') as scope:\n",
    "#             # feed to biLSTM\n",
    "#             c_outputs_A,c_last_states_A = build_model(sentences_A_char_emb_1,sentencesA_words_length_1,dropout_f)\n",
    "#             scope.reuse_variables()\n",
    "#             c_outputs_B,c_last_states_B = build_model(sentences_B_char_emb_1,sentencesB_words_length_1,dropout_f)\n",
    "\n",
    "# #             c_output_state_fw_A, c_output_state_bw_A = c_last_states_A\n",
    "\n",
    "#             # Each of the two tuples above has c and h, cell state and output respectively.\n",
    "# #             c_last_states_A_ct = tf.concat(2, [c_output_state_fw_A[0], c_output_state_bw_A[0]])\n",
    "#             # we use [0] because are interested with the c.\n",
    "# #             c_last_states_A_ct_ff = tf.reshape(c_last_states_A_ct[0], shape = ([-1, config.num_units * 2]))\n",
    "#             # feed to feedforward layer hidden states of sentences A\n",
    "#             with tf.variable_scope('siamese_char_ff_a') as scope:\n",
    "#                 # 50 x 50\n",
    "#                 C_ff_weights_a = tf.Variable(tf.random_uniform([config.num_units, FLAGS.char_embedding_dim], -1.0, 1.0),trainable=True,name=\"C_ff_weights_a\")\n",
    "#                 # 50\n",
    "#                 C_ff_bias_a = tf.Variable(tf.random_uniform([FLAGS.char_embedding_dim], -1.0, 1.0),trainable=True,name=\"C_ff_bias_a\")\n",
    "#                 # 960 x 50 * 50 x 50 \n",
    "#                 c_output_a = tf.add(tf.matmul(c_last_states_A[0].c, C_ff_weights_a), C_ff_bias_a)\n",
    "#                 # 960 x 16 x 50\n",
    "#                 c_output_a = tf.tanh(c_output_a)\n",
    "#                 # ? x 32 x 16 x 50\n",
    "#                 c_output_a = tf.reshape(c_output_a, shape = ([-1, max_sentence_len, FLAGS.char_embedding_dim]))\n",
    "            \n",
    "# #             c_output_state_fw_B, c_output_state_bw_B = c_last_states_B\n",
    "#             # TODO: Why [0] and [1]??\n",
    "# #             c_last_states_B_ct = tf.concat(2, [c_output_state_fw_B[0], c_output_state_bw_B[0]])\n",
    "# #             c_last_states_B_ct_ff = tf.reshape(c_last_states_B_ct[0], shape = ([-1, config.num_units * 2]))\n",
    "\n",
    "# #             # feed to feedforward layer hidden states of sentences B\n",
    "#             with tf.variable_scope('siamese_char_ff_b') as scope:\n",
    "#                 C_ff_weights_b = tf.Variable(tf.random_uniform([config.num_units, FLAGS.char_embedding_dim], -1.0, 1.0),trainable=True,name=\"C_ff_weights_b\")\n",
    "#                 C_ff_bias_b = tf.Variable(tf.random_uniform([FLAGS.char_embedding_dim], -1.0, 1.0),trainable=True,name=\"C_ff_bias_b\")\n",
    "#                 c_output_b = tf.add(tf.matmul(c_last_states_B[0].c, C_ff_weights_b), C_ff_bias_b)\n",
    "#                 c_output_b = tf.tanh(c_output_b)\n",
    "#                 c_output_b = tf.reshape(c_output_b, shape = ([-1, max_sentence_len, FLAGS.char_embedding_dim]))\n",
    "\n",
    "\n",
    "\n",
    "        # concatenate char + word embeddings here\n",
    "        # TODO: what does concat mean here? add embeddings element-wise or concat them but on which axis?\n",
    "#         final_emb_A = tf.add(sentences_A_word_emb, c_output_a)\n",
    "#         final_emb_B = tf.add(sentences_B_word_emb, c_output_b)\n",
    "        # final_emb_A = tf.concat(2, [sentences_A_word_emb, c_output_a])\n",
    "        # final_emb_B = tf.concat(2, [sentences_B_word_emb, c_output_b])\n",
    "\n",
    "        final_emb_A = sentences_A_word_emb\n",
    "        final_emb_B = sentences_B_word_emb\n",
    "        seq_len_A = sentencesA_length\n",
    "        seq_len_B = sentencesB_length\n",
    "\n",
    "        \n",
    "        # Feed the concatenation of embeddings to biLSTM\n",
    "        with tf.variable_scope('siamese_final') as scope:\n",
    "            outputs_A,last_states_A = build_model(final_emb_A,seq_len_A,dropout_f)\n",
    "            scope.reuse_variables()\n",
    "            outputs_B,last_states_B = build_model(final_emb_B,seq_len_B,dropout_f)\n",
    "\n",
    "#             # last_states_A_bw (30, 50)\n",
    "#             last_states_A_fw, last_states_A_bw =  last_states_A\n",
    "#             # last_states_A_ct (2, 30, 100)\n",
    "#             last_states_A_ct = tf.concat(2, [last_states_A_fw[0], last_states_A_bw[0]])\n",
    "#             # last_states_A_ct_c (30, 100)\n",
    "#             last_states_A_ct_c = last_states_A_ct[0]\n",
    "\n",
    "#             last_states_B_fw, last_states_B_bw =  last_states_B\n",
    "#             last_states_B_ct = tf.concat(2, [last_states_B_fw[0], last_states_B_bw[0]])\n",
    "#             last_states_B_ct_c = last_states_B_ct[0]            \n",
    "\n",
    "\n",
    "\n",
    "        prediction=tf.exp(tf.mul(-1.0,tf.reduce_mean(tf.abs(tf.sub(last_states_A[config.num_layer-1][1],last_states_B[config.num_layer-1][1])),1)))\n",
    "\n",
    "        cost = tf.reduce_mean(tf.square(tf.sub(prediction, labels)))\n",
    "\n",
    "        lr = tf.Variable(0.0,trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads,_ = tf.clip_by_global_norm(tf.gradients(cost,tvars),config.max_grad_norm)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        train_op = optimizer.apply_gradients(zip(grads,tvars),global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "        new_lr = tf.placeholder(tf.float32,shape=[],name='new_learning_rate')\n",
    "        lr_update = tf.assign(lr,new_lr)\n",
    "        \n",
    "        for v in tf.trainable_variables():\n",
    "            print(\">>:\", v.name)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        ## Launch training graph\n",
    "        with tf.Session(config=config_gpu) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            total_batch = int(len(zipped_train[0]) / config.batch_size)##this doesn't include the extra samples? It does. see below after the \"if\" block.\n",
    "            print('Total batch size: {}, data size: {}, batch size: {}'.format(total_batch,len(zipped_train[0]),config.batch_size))\n",
    "            print(config.max_grad_norm,config.keep_prob,config.lr_decay,config.lr_max_epoch,config.train_max_epoch,config.num_layer)\n",
    "            # train\n",
    "            prev_train_cost=1\n",
    "            prev_valid_cost=1\n",
    "            \n",
    "            patience = config.patience\n",
    "            train_costs = []\n",
    "            valid_costs = []\n",
    "            \n",
    "            \n",
    "            for epoch in range(config.train_max_epoch):\n",
    "                lr_decay = config.lr_decay**max(epoch+1-config.lr_max_epoch,0.0)\n",
    "                sess.run([lr,lr_update],feed_dict = {new_lr:config.learning_rate*lr_decay})\n",
    "                \n",
    "                print('Epoch {} Learning rate: {}'.format(epoch,sess.run(lr)))\n",
    "                \n",
    "                avg_cost=0.\n",
    "                \n",
    "                for i in range(total_batch):\n",
    "#                     print(\"i:\", i)\n",
    "                    start = i*config.batch_size\n",
    "                    end = (i+1)*config.batch_size\n",
    "                    next_batch_input = next_batch(start,end,zipped_train)\n",
    "\n",
    "                    _,train_cost= sess.run([train_op,cost], feed_dict={   \n",
    "#                     cost,prediction,c_output_b, c_output_a= sess.run([cost,prediction,c_output_b, c_output_a], feed_dict={   \n",
    "#                     c_output_a,c_output_a_t, \n",
    "#                     c_output_a,c_output_a_t,c_output_a_m, C_ff_bias_a, C_ff_weights_a,sentences_A_char_emb_1, sentencesA_words_length_1,c_last_states_A= sess.run([sentences_A_char_emb_1, sentencesA_words_length_1,c_last_states_A,c_output_a_m, C_ff_bias_a, C_ff_weights_a,c_output_a_t, c_output_a], feed_dict={   \n",
    "#                     last_states_A_ct_c, sentencesA_words_length, sentencesA_words_length_1, C, sentences_A_char_emb_1, train_cost,  prediction, last_states_A_ct, last_states_A_bw, final_emb_A, c_last_states_A_ct_ff, c_last_states_A_ct, c_output_state_fw_A, sentences_A_char_emb,sentences_words_A, sentences_A_word_emb= sess.run([last_states_A_ct_c, sentencesA_words_length, sentencesA_words_length_1, C, sentences_A_char_emb_1, cost, prediction,  last_states_A_ct, last_states_A_bw, final_emb_A, c_last_states_A_ct_ff, c_last_states_A_ct, c_output_state_fw_A, sentences_A_char_emb,sentences_words_A, sentences_A_word_emb], feed_dict={                                         \n",
    "                            sentences_A: next_batch_input.senA_word_ids,\n",
    "                            sentencesA_length: next_batch_input.senA_len,\n",
    "                            sentences_B: next_batch_input.senB_word_ids,\n",
    "                            sentencesB_length: next_batch_input.senB_len,\n",
    "                            \n",
    "#                             sentences_words_A: next_batch_input.senA_char_ids,\n",
    "#                             sentencesA_words_length: next_batch_input.senA_words_len,\n",
    "#                             sentences_words_B: next_batch_input.senB_char_ids,\n",
    "#                             sentencesB_words_length: next_batch_input.senB_words_len,\n",
    "                            labels: next_batch_input.relatedness_scores,\n",
    "                            dropout_f: config.keep_prob,\n",
    "                            embedding_placeholder: init_W\n",
    "                        })\n",
    "#                     avg_cost += train_cost\n",
    "            \n",
    "#                     print(\"sentences_A_char_emb_1\", sentences_A_char_emb_1.shape)\n",
    "#                     print(\"sentencesA_words_length_1\", sentencesA_words_length_1.shape)\n",
    "#                     print(\"c_last_states_A\", len(c_last_states_A))\n",
    "# #                     print(\"c_last_states_A\", c_last_states_A[0].c.shape)\n",
    "# #                     print(\"C_ff_bias_a\", C_ff_bias_a[0].c.shape)\n",
    "# #                     print(\"c_output_a_m\", c_output_a_m.shape)\n",
    "#                     print(\"c_output_a_t\", c_output_a_t.shape)\n",
    "#                     print(\"c_output_a\", c_output_a.shape)\n",
    "#                     print(\"c_output_b\", c_output_b.shape)\n",
    "#                     print(\"prediction\", prediction.shape)\n",
    "#                     print(\"cost\", cost)\n",
    "#                     break\n",
    "                    \n",
    "                start = total_batch*config.batch_size\n",
    "                end = len(zipped_train[0])\n",
    "                #check if the last trailing batch and handle it\n",
    "                if not start == end:\n",
    "                    next_batch_input = next_batch(start,end,zipped_train)\n",
    "                    _,train_cost= sess.run([train_op,cost], feed_dict={                                         \n",
    "                            sentences_A: next_batch_input.senA_word_ids,\n",
    "                            sentencesA_length: next_batch_input.senA_len,\n",
    "                            sentences_B: next_batch_input.senB_word_ids,\n",
    "                            sentencesB_length: next_batch_input.senB_len,\n",
    "                            \n",
    "#                             sentences_words_A: next_batch_input.senA_char_ids,\n",
    "#                             sentencesA_words_length: next_batch_input.senA_words_len,\n",
    "#                             sentences_words_B: next_batch_input.senB_char_ids,\n",
    "#                             sentencesB_words_length: next_batch_input.senB_words_len,\n",
    "                            labels: next_batch_input.relatedness_scores,\n",
    "                            dropout_f: config.keep_prob,\n",
    "                            embedding_placeholder: init_W\n",
    "                        })\n",
    "                    avg_cost += train_cost\n",
    "                \n",
    "                if prev_train_cost >  avg_cost / total_batch: \n",
    "                    print('Average cost:\\t{} >'.format(avg_cost / total_batch))\n",
    "                else: \n",
    "                    print('Average cost:\\t{} <'.format(avg_cost / total_batch))\n",
    "\n",
    "                prev_train_cost = avg_cost / total_batch\n",
    "                \n",
    "                train_costs.append(avg_cost)\n",
    "\n",
    "                \n",
    "                # validation\n",
    "                next_batch_input = next_batch(0, len(zipped_dev[0]), zipped_dev)\n",
    "                valid_cost,valid_predict=sess.run([cost,prediction],feed_dict={\n",
    "                        sentences_A: next_batch_input.senA_word_ids,\n",
    "                        sentencesA_length: next_batch_input.senA_len,\n",
    "                        sentences_B: next_batch_input.senB_word_ids,\n",
    "                        sentencesB_length: next_batch_input.senB_len,\n",
    "\n",
    "#                         sentences_words_A: next_batch_input.senA_char_ids,\n",
    "#                         sentencesA_words_length: next_batch_input.senA_words_len,\n",
    "#                         sentences_words_B: next_batch_input.senB_char_ids,\n",
    "#                         sentencesB_words_length: next_batch_input.senB_words_len,\n",
    "                        labels: next_batch_input.relatedness_scores,\n",
    "                        dropout_f: config.keep_prob,\n",
    "                        embedding_placeholder: init_W\n",
    "                })\n",
    "                if prev_valid_cost > valid_cost: \n",
    "                    print('Valid cost:\\t{} >'.format(valid_cost))\n",
    "                else: \n",
    "                    print('Valid cost:\\t{} <'.format(valid_cost))\n",
    "                prev_valid_cost=valid_cost\n",
    "                \n",
    "                valid_costs.append(valid_cost)\n",
    "                \n",
    "                # early stopping\n",
    "                if patience == 0:\n",
    "                    print(\"Lost patience:\", patience)\n",
    "                    break\n",
    "                if prev_valid_cost > valid_cost:\n",
    "                    patience -= 1\n",
    "                else:\n",
    "                    patience = 5\n",
    "                print(\"patience:\", patience)\n",
    "#                 break\n",
    "            saver.save(sess, FLAGS.save_path+FLAGS.model_name,global_step=config.train_max_epoch)\n",
    "\n",
    "            # test\n",
    "            next_batch_input = next_batch(0, len(zipped_test[0]), zipped_test)\n",
    "            test_cost,test_predict=sess.run([cost,prediction],feed_dict={\n",
    "                    sentences_A: next_batch_input.senA_word_ids,\n",
    "                    sentencesA_length: next_batch_input.senA_len,\n",
    "                    sentences_B: next_batch_input.senB_word_ids,\n",
    "                    sentencesB_length: next_batch_input.senB_len,\n",
    "\n",
    "#                     sentences_words_A: next_batch_input.senA_char_ids,\n",
    "#                     sentencesA_words_length: next_batch_input.senA_words_len,\n",
    "#                     sentences_words_B: next_batch_input.senB_char_ids,\n",
    "#                     sentencesB_words_length: next_batch_input.senB_words_len,\n",
    "                    labels: next_batch_input.relatedness_scores,\n",
    "                    dropout_f: config.keep_prob,\n",
    "                    embedding_placeholder: init_W         \n",
    "            })\n",
    "            print(test_cost)\n",
    "\n",
    "\n",
    "            \n",
    "with open(FLAGS.result_path + FLAGS.model_name+'.txt','w') as fw:\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for _ in range(len(test_predict)):\n",
    "        fw.write(str(next_batch_input.relatedness_scores[_])+'\\t'+str(test_predict[_])+'\\n')\n",
    "        labels.append(next_batch_input.relatedness_scores[_])\n",
    "        preds.append(test_predict[_])\n",
    "    print(\"Pearson:\", pearsonr(labels,preds))\n",
    "stop = timeit.default_timer()\n",
    "print(\"Execution time:\", stop - start)\n",
    "\n",
    "\n",
    "y1 = train_costs\n",
    "y2 = valid_costs\n",
    "x_axis = range(1, len(y1)+1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, y1, label='Train Cost')\n",
    "ax.plot(x_axis, y2, label='Validation Cost')\n",
    "ax.legend()\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training vs Validation Cost')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig(FLAGS.result_path + FLAGS.model_name+\"_\"+train_max_epoch+\".png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = read_input_file(FLAGS.test_data)\n",
    "cnt = int(FLAGS.cnt)\n",
    "with open(FLAGS.result_path + FLAGS.model_name+'.txt', 'r') as f:\n",
    "    a = []\n",
    "    b = []\n",
    "    for line in f:\n",
    "        a.append(float(line.strip().split('\\t')[0]))\n",
    "        b.append(float(line.strip().split('\\t')[1]))\n",
    "    #most dissimilar/similar actual/predictions values\n",
    "    res = [abs(a[i] - b[i]) for i in range(len(a))]\n",
    "    sort = sorted(range(len(res)), key=lambda k: res[k], reverse = True)\n",
    "    firstn = sort[0:cnt]\n",
    "    lastn = sort[-(cnt):len(sort)]\n",
    "    lastn = lastn[::-1]\n",
    "    \n",
    "    #prediction scores\n",
    "    predscores = sorted(range(len(b)), key=lambda k: b[k], reverse = True)\n",
    "    highpreds = predscores[0:cnt]\n",
    "    lowpreds = predscores[-(cnt):len(predscores)]\n",
    "    lowpreds = lowpreds[::-1]\n",
    "with open(FLAGS.result_path + FLAGS.model_name+'_samples.txt', 'w') as f:\n",
    "#     print(\"Most dissimilar (actual - predicted)\\n\")\n",
    "    f.write(\"Most dissimilar (actual - predicted)\\n\")\n",
    "    for i in range(len(test_data.sentences_A)):\n",
    "    #     print(i)\n",
    "        txt = str(next_batch_input.relatedness_scores[firstn[i]])+\"\\t\"+str(test_predict[firstn[i]])+\"\\t\"+ str(\" \".join(test_data.sentences_A[firstn[i]]))+\"\\t\"+str(\" \".join(test_data.sentences_B[firstn[i]]))\n",
    "#         print(txt)\n",
    "        f.write(txt+\"\\n\")\n",
    "        if i == cnt-1:\n",
    "            break\n",
    "\n",
    "\n",
    "#     print(\"Most similar (actual - predicted)\\n\")\n",
    "    f.write(\"Most similar (actual - predicted)\\n\")\n",
    "    length = len(test_data.sentences_A)\n",
    "    for i in range(length):\n",
    "    #     print(i)\n",
    "        txt = str(next_batch_input.relatedness_scores[lastn[i]])+\"\\t\"+str(test_predict[lastn[i]])+\"\\t\"+ str(\" \".join(test_data.sentences_A[lastn[i]]))+\"\\t\"+str(\" \".join(test_data.sentences_B[lastn[i]]))\n",
    "#         print(txt)\n",
    "        f.write(txt+\"\\n\")\n",
    "        if i == cnt-1:\n",
    "            break\n",
    "#     print(\"Most dissimilar sentence pairs as predicted\\n\")\n",
    "    f.write(\"Most dissimilar sentence pairs as predicted\\n\")\n",
    "    for i in range(len(test_data.sentences_A)):\n",
    "    #     print(i)\n",
    "        txt = str(next_batch_input.relatedness_scores[lowpreds[i]])+\"\\t\"+str(test_predict[lowpreds[i]])+\"\\t\"+ str(\" \".join(test_data.sentences_A[lowpreds[i]]))+\"\\t\"+str(\" \".join(test_data.sentences_B[lowpreds[i]]))\n",
    "#         print(txt)\n",
    "        f.write(txt+\"\\n\")\n",
    "        if i == cnt-1:\n",
    "            break\n",
    "\n",
    "\n",
    "#     print(\"Most similar sentence pairs as predicted\\n\")\n",
    "    f.write(\"Most similar sentence pairs as predicted\\n\")\n",
    "    length = len(test_data.sentences_A)\n",
    "    for i in range(length):\n",
    "    #     print(i)\n",
    "        txt = str(next_batch_input.relatedness_scores[highpreds[i]])+\"\\t\"+str(test_predict[highpreds[i]])+\"\\t\"+ str(\" \".join(test_data.sentences_A[highpreds[i]]))+\"\\t\"+str(\" \".join(test_data.sentences_B[highpreds[i]]))\n",
    "#         print(txt)\n",
    "        f.write(txt+\"\\n\")\n",
    "        if i == cnt-1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
